{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_files \ntrain_dir= '../input/fruits/fruits-360/Training'\ntest_dir= '../input/fruits/fruits-360/Test'\n\ndef load_dataset(path):\n    data=load_files(path)\n    files=np.array(data['filenames'])\n    targets=np.array(data['target'])\n    target_labels=np.array(data['target_names'])\n    return files, targets, target_labels\n\nx_train,y_train,target_labels= load_dataset(train_dir) \nx_test,y_test,_=load_dataset(test_dir)\nprint(\"loading complete1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training set size : ' , x_train.shape[0])\nprint('Testing set size : ', x_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_of_classes = len(np.unique(y_train))\nno_of_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import np_utils\ny_train=np_utils.to_categorical(y_train,no_of_classes)\ny_test=np_utils.to_categorical(y_test,no_of_classes)\ny_train[0]\nx_test,x_valid=x_test[11000:],x_test[:11000]\ny_test,y_valid=y_test[11000:],y_test[:11000]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Vaildation X : ',x_valid.shape)\nprint('Vaildation y :',y_vaild.shape)\nprint('Test X : ',x_test.shape)\nprint('Test y : ',y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import array_to_img, img_to_array,load_img\n\ndef convert_image_to_array(files):\n    images_as_array=[]\n    for file in files:\n        images_as_array.append(img_to_array(load_img(file)))\n    return images_as_array\nx_train=np.array(convert_image_to_array(x_train))\nprint('Training Set Shape :', x_train.shape)\n\ny_train=np.array(convert_image_to_array(x_valid))\nprint('Validation Set Shape :', x_valid.shape)\n\nx_test=np.array(convert_image_to_array(x_test))\nprint('Test Set Shape :',x_test.shape)\n\nprint('1st training image shape',x_train[0].shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('1st training image as array',x_train[0]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = x_train.astype('float32')/255\nx_valid = x_valid.astype('float32')/255\nx_test = x_test.astype('float32')/255\nx_train[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig = plt.figure(figsize =(30,5))\nfor i in range(10):\n    ax = fig.add_subplot(2,5,i+1,xticks=[],yticks=[])\n    ax.imshow(np.squeeze(x_train[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras.layers import Activation, Dense, Flatten, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import backend as K\n\nmodel = Sequential()\nmodel.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(100,100,3),padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(150))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(81,activation = 'softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\nprint('Compiled!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nbatch_size = 32\n\ncheckpointer = ModelCheckpoint(filepath = 'cnn_from_scratch_fruits.hdf5', verbose = 1, save_best_only = True)\n\nhistory = model.fit(x_train,y_train,\n        batch_size = 32,\n        epochs=30,\n        validation_data=(x_valid, y_vaild),\n        callbacks = [checkpointer],\n        verbose=2, shuffle=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(x_test, y_test, verbose=0)\nprint('\\n', 'Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(16, 9))\nfor i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(x_test[idx]))\n    pred_idx = np.argmax(y_pred[idx])\n    true_idx = np.argmax(y_test[idx])\n    ax.set_title(\"{} ({})\".format(target_labels[pred_idx], target_labels[true_idx]),\n                 color=(\"green\" if pred_idx == true_idx else \"red\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nplt.figure(1)  \n\n\nplt.subplot(211)  \nplt.plot(history.history['acc'])  \nplt.plot(history.history['val_acc'])  \nplt.title('model accuracy')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'test'], loc='upper left') \n\nplt.subplot(212)  \nplt.plot(history.history['loss'])  \nplt.plot(history.history['val_loss'])  \nplt.title('model loss')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'test'], loc='upper left')  \nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}